# Proyecto 1: OrganizaciÃ³n e IndexaciÃ³n Eficiente de Archivos

**Universidad:** UTEC  
**Curso:** Bases de Datos 2 (BD2)  
**Fecha:** Octubre 2025  
**Dataset:** Kaggle Restaurants Dataset (9,551 registros)

---

## 1. IntroducciÃ³n

### 1.1 Objetivo del Proyecto

El objetivo principal de este proyecto es implementar y comparar diferentes tÃ©cnicas de organizaciÃ³n e indexaciÃ³n de archivos para optimizar la gestiÃ³n, almacenamiento y recuperaciÃ³n eficiente de datos estructurados. Se desarrollÃ³ un mini gestor de bases de datos que soporta operaciones fundamentales (inserciÃ³n, bÃºsqueda, eliminaciÃ³n) utilizando cuatro tÃ©cnicas de indexaciÃ³n distintas, permitiendo analizar su desempeÃ±o en escenarios reales.

### 1.2 DescripciÃ³n de la AplicaciÃ³n

Se desarrollÃ³ un **sistema de gestiÃ³n de base de datos de restaurantes** que permite:

- **Almacenar informaciÃ³n de 9,551 restaurantes** con 21 atributos (ID, nombre, ciudad, rating, etc.)
- **Consultar restaurantes** por ID, rango de IDs, o atributos especÃ­ficos
- **Insertar nuevos restaurantes** manteniendo la estructura del Ã­ndice
- **Eliminar restaurantes** de forma eficiente
- **Comparar el desempeÃ±o** de 4 tÃ©cnicas de indexaciÃ³n diferentes

**Caso de Uso Real:** Sistema de recomendaciÃ³n de restaurantes donde la velocidad de bÃºsqueda es crÃ­tica. Por ejemplo:

- BÃºsqueda rÃ¡pida de restaurante por ID para mostrar detalles
- BÃºsqueda por rango para paginaciÃ³n (mostrar restaurantes 1000-1100)
- InserciÃ³n de nuevos restaurantes sin afectar performance
- EliminaciÃ³n de restaurantes cerrados

### 1.3 Resultados Esperados

Al aplicar las tÃ©cnicas de indexaciÃ³n, se espera:

1. **Reducir accesos a disco** comparado con bÃºsqueda secuencial completa
2. **Mejorar tiempo de respuesta** en bÃºsquedas por clave primaria (< 10ms)
3. **Optimizar bÃºsquedas por rango** aprovechando el orden de los Ã­ndices
4. **Mantener eficiencia en inserciones** sin degradar performance significativamente
5. **Identificar la tÃ©cnica Ã³ptima** para cada tipo de operaciÃ³n

---

## 2. TÃ©cnicas de IndexaciÃ³n Implementadas

### 2.1 Sequential File

**DescripciÃ³n:**  
Organiza los registros secuencialmente en disco ordenados por clave primaria. Las nuevas inserciones se almacenan en un Ã¡rea de overflow que se fusiona periÃ³dicamente con el archivo principal.

**Estructura:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Archivo Principal (Ordenado)      â”‚
â”‚  [Reg1] [Reg2] ... [RegN]          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Ãrea de Overflow (Inserciones)    â”‚
â”‚  [RegN+1] [RegN+2] ...              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Algoritmo de BÃºsqueda (search):**

```python
def search(key):
    # 1. BÃºsqueda binaria en archivo principal
    resultado = binary_search_disk(key)
    if resultado:
        return resultado

    # 2. BÃºsqueda lineal en overflow
    for registro in overflow:
        if registro.key == key:
            return registro

    return None
```

**Algoritmo de InserciÃ³n (add):**

```python
def add(registro):
    # 1. Agregar a Ã¡rea de overflow
    overflow.append(registro)
    disk_write(overflow_file, registro)  # 1 write

    # 2. Si overflow lleno, reconstruir
    if len(overflow) >= THRESHOLD:
        rebuild_index()  # N writes
```

**Algoritmo de EliminaciÃ³n (remove):**

```python
def remove(key):
    # 1. Buscar en archivo principal
    records = load_all_blocks()  # N reads
    records = [r for r in records if r.key != key]

    # 2. Reescribir archivo sin el registro
    rebuild_file(records)  # N writes
```

**Complejidad Temporal:**

- BÃºsqueda: O(log N) en principal + O(K) en overflow
- InserciÃ³n: O(1) amortizado, O(N) en reconstrucciÃ³n
- EliminaciÃ³n: O(N) - requiere reescribir archivo completo
- Range: O(log N + M) donde M = registros en rango

**Complejidad de I/O:**

- BÃºsqueda: 1 read (bÃºsqueda binaria eficiente)
- InserciÃ³n: 1 write normal, N writes en reconstrucciÃ³n
- EliminaciÃ³n: **N reads + N writes** (muy costoso)
- Range: 1 read (registros contiguos en disco)

---

### 2.2 ISAM (Indexed Sequential Access Method) - 3 Niveles

**DescripciÃ³n:**  
Ãndice estÃ¡tico multinivel que mantiene 3 niveles de indexaciÃ³n: L2 (Ã­ndice superior), L1 (Ã­ndice de buckets), y Buckets (datos). Las inserciones post-construcciÃ³n se manejan con pÃ¡ginas de overflow encadenadas.

**Estructura:**

```
Nivel 1 (L2 - RAM):     [10] [50] [90] ...
                         â†“    â†“    â†“
Nivel 2 (L1 - RAM):   [10,12,14] [50,52,54] [90,92,94]
                         â†“          â†“          â†“
Nivel 3 (Buckets):   [10-19]    [50-59]    [90-99]
                         â†“ overflow
                     [105,107]
```

**ParÃ¡metros:**

- `fanout = 20`: Registros por bucket
- `fanout_l2 = 5`: Buckets por entrada L2

**Algoritmo de BÃºsqueda (search):**

```python
def search(key):
    # 1. BÃºsqueda binaria en L2 (RAM) - 0 I/O
    l2_idx = binary_search(index_l2, key)

    # 2. BÃºsqueda binaria en L1 (RAM) - 0 I/O
    l1_start = l2_idx * fanout_l2
    l1_idx = binary_search(index_l1[l1_start:], key)

    # 3. Leer bucket del disco - 1 I/O READ
    bucket = disk_read_bucket(l1_idx)

    # 4. BÃºsqueda en bucket (RAM) - 0 I/O
    return binary_search(bucket, key)
```

**Algoritmo de InserciÃ³n (add):**

```python
def add(registro):
    # 1. Encontrar bucket correspondiente (RAM)
    bucket_idx = find_bucket_index(registro.key)

    # 2. Agregar a overflow de ese bucket
    overflow[bucket_idx].append(registro)

    # 3. Escribir overflow a disco - 1 I/O WRITE
    disk_write_overflow(bucket_idx, registro)
```

**Algoritmo de EliminaciÃ³n (remove):**

```python
def remove(key):
    # 1. Buscar bucket (Ã­ndices en RAM) - 0 I/O
    bucket_idx = find_bucket_index(key)

    # 2. Leer bucket - 1 I/O READ
    bucket = disk_read_bucket(bucket_idx)

    # 3. Marcar como eliminado (lazy deletion)
    mark_deleted(bucket, key)

    # No requiere reescritura inmediata
```

**Complejidad Temporal:**

- BÃºsqueda: O(log L2 + log L1 + log B) â‰ˆ O(log N)
- InserciÃ³n: O(log L2 + log L1) = O(log N)
- EliminaciÃ³n: O(log N)
- Range: O(log N + M/B) donde B = bucket size

**Complejidad de I/O:**

- BÃºsqueda: **1 read** (acceso directo al bucket)
- InserciÃ³n: **1 write** (solo overflow)
- EliminaciÃ³n: **1 read, 0 writes** (lazy deletion)
- Range: **1 read por bucket** en el rango

---

### 2.3 Extendible Hashing

**DescripciÃ³n:**  
TÃ©cnica de hashing dinÃ¡mico que utiliza un directorio extensible para manejar colisiones. La profundidad global aumenta cuando un bucket se llena, duplicando el tamaÃ±o del directorio.

**Estructura:**

```
Directorio (Depth=2):
  00 â†’ Bucket A [keys: 4, 8, 12]
  01 â†’ Bucket B [keys: 1, 5, 9]
  10 â†’ Bucket C [keys: 2, 6, 10]
  11 â†’ Bucket D [keys: 3, 7, 11]

Hash function: h(key) = key % 2^depth
```

**Algoritmo de BÃºsqueda (search):**

```python
def search(key):
    # 1. Calcular hash (RAM)
    hash_val = hash(key) % (2 ** global_depth)

    # 2. Obtener bucket_id del directorio (RAM)
    bucket_id = directory[hash_val]

    # 3. Leer bucket del disco - 1 I/O READ
    bucket = disk_read_bucket(bucket_id)

    # 4. Buscar en bucket
    return linear_search(bucket, key)
```

**Algoritmo de InserciÃ³n (add):**

```python
def add(registro):
    hash_val = hash(registro.key) % (2 ** global_depth)
    bucket_id = directory[hash_val]
    bucket = disk_read_bucket(bucket_id)

    if bucket.is_full():
        # Split bucket y duplicar directorio si necesario
        if bucket.local_depth == global_depth:
            global_depth += 1
            directory = duplicate_directory()

        split_bucket(bucket_id)
        redistribute_records()

    bucket.append(registro)
    disk_write_bucket(bucket_id, bucket)  # 1 write
```

**Algoritmo de EliminaciÃ³n (remove):**

```python
def remove(key):
    # 1. Calcular hash y obtener bucket
    hash_val = hash(key) % (2 ** global_depth)
    bucket_id = directory[hash_val]

    # 2. Leer todos los buckets para rebuild
    all_records = []
    for bid in unique_buckets:
        all_records.extend(disk_read_bucket(bid))  # N reads

    # 3. Filtrar y reconstruir
    all_records = [r for r in all_records if r.key != key]
    rebuild_from_scratch(all_records)  # N writes
```

**Complejidad Temporal:**

- BÃºsqueda: O(1) promedio
- InserciÃ³n: O(1) amortizado, O(N) en split
- EliminaciÃ³n: O(N) - requiere rebuild completo
- Range: **No soportado** (hash destruye orden)

**Complejidad de I/O:**

- BÃºsqueda: **1 read** (acceso directo por hash)
- InserciÃ³n: **1-2 writes** (normal o con split)
- EliminaciÃ³n: **N reads + N writes** (rebuild)
- Range: No aplicable

---

### 2.4 B+ Tree

**DescripciÃ³n:**  
Ãrbol balanceado donde todos los datos residen en las hojas, que estÃ¡n enlazadas para facilitar bÃºsquedas por rango. Los nodos internos solo contienen claves para navegaciÃ³n.

**Estructura:**

```
Nodo Interno (order=4):
         [20, 40, 60]
        /    |    |    \
    Hoja1  Hoja2 Hoja3 Hoja4
      â†“      â†“      â†“      â†“
   [1-19] [20-39] [40-59] [60+]
     â†”      â†”      â†”      â†”
   (Hojas enlazadas para range queries)
```

**Algoritmo de BÃºsqueda (search):**

```python
def search(key, node=root):
    if node.is_leaf:
        return linear_search(node.keys, key)

    # Navegar por Ã¡rbol (en RAM si cabe)
    child_idx = find_child_index(node, key)
    return search(key, node.children[child_idx])
```

**Algoritmo de InserciÃ³n (add):**

```python
def add(registro, node=root):
    if node.is_leaf:
        node.keys.insert_sorted(registro)

        if node.is_full():
            split_leaf(node)  # Split y propagar hacia arriba
    else:
        child = find_child(node, registro.key)
        add(registro, child)

        if child.is_full():
            split_internal(child)
```

**Algoritmo de EliminaciÃ³n (remove):**

```python
def remove(key):
    # 1. Buscar hoja que contiene key (Ã¡rbol en RAM)
    leaf = find_leaf(key)

    # 2. Eliminar de hoja
    leaf.keys.remove(key)

    # 3. Rebalancear si necesario (merge o redistribuciÃ³n)
    if leaf.is_underflow():
        rebalance(leaf)
```

**Algoritmo de Range Search:**

```python
def range_search(begin, end):
    # 1. Buscar hoja inicial
    leaf = find_leaf(begin)

    # 2. Recorrer hojas enlazadas
    result = []
    while leaf and leaf.keys[0] <= end:
        result.extend([k for k in leaf.keys if begin <= k <= end])
        leaf = leaf.next  # Siguiente hoja enlazada

    return result
```

**Complejidad Temporal:**

- BÃºsqueda: O(log_m N) donde m = order
- InserciÃ³n: O(log_m N)
- EliminaciÃ³n: O(log_m N)
- Range: O(log_m N + M) donde M = registros en rango

**Complejidad de I/O (Ã¡rbol en RAM):**

- BÃºsqueda: **0 reads** (Ã¡rbol completo en RAM)
- InserciÃ³n: **0 writes** (persistencia diferida)
- EliminaciÃ³n: **0 reads, 0 writes** (en RAM)
- Range: **0 reads** (recorrido de hojas en RAM)

---

## 3. AnÃ¡lisis Comparativo TeÃ³rico

### 3.1 Tabla Comparativa de Complejidad

| OperaciÃ³n       | Sequential       | ISAM         | Ext Hash        | B+ Tree          |
| --------------- | ---------------- | ------------ | --------------- | ---------------- |
| **BÃºsqueda**    | O(log N)         | O(log N)     | **O(1)**        | O(log N)         |
| **InserciÃ³n**   | O(1) amort       | O(log N)     | **O(1) amort**  | O(log N)         |
| **EliminaciÃ³n** | **O(N)**         | O(log N)     | **O(N)**        | O(log N)         |
| **Range**       | **O(log N + M)** | O(log N + M) | âŒ No soportado | **O(log N + M)** |

### 3.2 AnÃ¡lisis de Accesos a Memoria Secundaria

#### BÃºsqueda (SELECT por clave):

- **Sequential**: 1 read (bÃºsqueda binaria eficiente en bloques)
- **ISAM**: **1 read** (acceso directo al bucket calculado)
- **Ext Hash**: **1 read** (acceso directo por hash)
- **B+ Tree**: 0 reads si el Ã¡rbol estÃ¡ en RAM, log_m(N) reads si estÃ¡ en disco

**Ganador teÃ³rico**: Ext Hash (O(1) hash directo)

#### InserciÃ³n (INSERT):

- **Sequential**: 1 write normal, N writes en reconstrucciÃ³n periÃ³dica
- **ISAM**: **1 write** (solo en overflow)
- **Ext Hash**: 1-2 writes (normal) o N writes (si hay split)
- **B+ Tree**: 0 writes (RAM), log_m(N) writes (disco)

**Ganador teÃ³rico**: ISAM (1 write consistente)

#### EliminaciÃ³n (DELETE):

- **Sequential**: **N reads + N writes** (rebuild completo)
- **ISAM**: **1 read + 0 writes** (lazy deletion)
- **Ext Hash**: **N reads + N writes** (rebuild completo)
- **B+ Tree**: 0 I/O (RAM), log_m(N) I/O (disco)

**Ganador teÃ³rico**: ISAM o B+ Tree (eliminaciÃ³n eficiente)

#### Range Search (SELECT ... BETWEEN):

- **Sequential**: **1 read** (datos contiguos)
- **ISAM**: ceil(M/B) reads donde B = bucket size
- **Ext Hash**: âŒ **No soportado** (hash destruye orden)
- **B+ Tree**: 0 reads (hojas enlazadas en RAM)

**Ganador teÃ³rico**: Sequential o B+ Tree

---

## 4. ImplementaciÃ³n del Sistema

### 4.1 Parser SQL

Se implementÃ³ un parser que transforma consultas SQL a objetos AST (Abstract Syntax Tree) ejecutables.

**Sintaxis Soportada:**

```sql
-- Crear tabla
CREATE TABLE nombre USING {sequential|isam|extendiblehash|bplustree}

-- Cargar datos
LOAD FROM 'ruta/archivo.csv' INTO nombre

-- Consultas
SELECT * FROM nombre
SELECT * FROM nombre WHERE columna = valor
SELECT * FROM nombre WHERE columna BETWEEN valor1 AND valor2

-- ModificaciÃ³n
INSERT INTO nombre (cols) VALUES (vals)
DELETE FROM nombre WHERE columna = valor
```

**ImplementaciÃ³n del Parser:**

```python
# sql/parser.py
class Parser:
    PATTERNS = {
        'CREATE': re.compile(r"CREATE TABLE (\w+) USING (\w+)"),
        'LOAD': re.compile(r"LOAD FROM '(.+)' INTO (\w+)"),
        'SELECT_ALL': re.compile(r"SELECT \* FROM (\w+)$"),
        'SELECT_WHERE': re.compile(r"SELECT \* FROM (\w+) WHERE (.+) = (.+)"),
        'SELECT_RANGE': re.compile(r"SELECT \* FROM (\w+) WHERE (.+) BETWEEN (.+) AND (.+)"),
        'INSERT': re.compile(r"INSERT INTO (\w+) \((.+)\) VALUES \((.+)\)"),
        'DELETE': re.compile(r"DELETE FROM (\w+) WHERE (.+) = (.+)")
    }

    def parse(self, sql: str) -> ASTNode:
        sql = sql.strip()

        for pattern_type, pattern in self.PATTERNS.items():
            match = pattern.match(sql)
            if match:
                return self._create_ast_node(pattern_type, match.groups())

        raise ValueError(f"SQL no soportado: {sql}")
```

**Flujo de EjecuciÃ³n:**

```
SQL Query â†’ Parser â†’ AST Node â†’ Planner â†’ Executor â†’ Result
```

Ejemplo:

```python
sql = "SELECT * FROM restaurants WHERE id = 123"
ast = parser.parse(sql)  # SelectEq(table='restaurants', column='id', value=123)
plan = planner.plan(ast)
result = executor.execute(plan)  # {'rows': [...], 'io': {...}, 'time_ms': 0.5}
```

### 4.2 Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           Frontend (Streamlit)              â”‚
â”‚  - Editor SQL                               â”‚
â”‚  - VisualizaciÃ³n de resultados              â”‚
â”‚  - MÃ©tricas de I/O                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“ HTTP
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Backend API (FastAPI)               â”‚
â”‚  - Endpoint /query                          â”‚
â”‚  - Endpoint /load                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          SQL Engine                         â”‚
â”‚  Parser â†’ AST â†’ Planner â†’ Executor         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Index Manager                       â”‚
â”‚  - Sequential, ISAM, Hash, B+Tree          â”‚
â”‚  - Operaciones: search, add, remove        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Disk Manager                        â”‚
â”‚  - Buffer Pool (LRU)                       â”‚
â”‚  - I/O Metrics Counter                     â”‚
â”‚  - Page Management                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Storage (Archivos .dat)            â”‚
â”‚  - restaurants_seq.dat                     â”‚
â”‚  - restaurants_isam_buckets.dat            â”‚
â”‚  - restaurants_hash.dat                    â”‚
â”‚  - restaurants_bplustree.dat               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.3 Optimizaciones Implementadas

1. **Buffer Pool con LRU**: Cachea pÃ¡ginas frecuentemente accedidas
2. **Lazy Deletion en ISAM**: Marca registros eliminados sin reescribir
3. **Ãndices en RAM**: L1 y L2 de ISAM, directorio de Hash en memoria
4. **BÃºsqueda Binaria**: En estructuras ordenadas (Sequential, ISAM buckets)
5. **Hojas Enlazadas en B+ Tree**: Range queries sin recorrer Ã¡rbol completo

---

## 5. Resultados Experimentales

### 5.1 ConfiguraciÃ³n del Experimento

- **Dataset**: Kaggle Restaurants Dataset
- **Registros**: 9,551 restaurantes
- **Atributos**: 21 columnas (ID, nombre, ciudad, rating, ubicaciÃ³n, etc.)
- **Clave Primaria**: `Restaurant ID` (entero)
- **Hardware**: PC estÃ¡ndar con SSD
- **Software**: Python 3.13, Windows 11

### 5.2 Operaciones Evaluadas

1. **SELECT =**: BÃºsqueda por clave primaria (3 bÃºsquedas promediadas)
2. **RANGE (10)**: BÃºsqueda de 10 registros consecutivos
3. **RANGE (100)**: BÃºsqueda de 100 registros consecutivos
4. **RANGE (1K)**: BÃºsqueda de 1,000 registros consecutivos
5. **INSERT**: InserciÃ³n de 1 registro nuevo
6. **DELETE**: EliminaciÃ³n de 1 registro por clave

### 5.3 Resultados: Tiempo de EjecuciÃ³n (ms)

| Ãndice         | SELECT =    | RANGE (10) | RANGE (100) | RANGE (1K)  | INSERT      | DELETE        |
| -------------- | ----------- | ---------- | ----------- | ----------- | ----------- | ------------- |
| **Sequential** | 7.11        | 2.07       | 1.98        | 2.08        | 1.69        | **375.07** âš ï¸ |
| **ISAM**       | 7.38        | 1.03       | 0.91        | **0.77** ğŸ† | 0.68        | **1.13** ğŸ†   |
| **Ext Hash**   | 7.41        | 0.99       | 1.06        | 0.93        | 2.49        | **383.70** âš ï¸ |
| **B+ Tree**    | **0.78** ğŸ† | 2.09       | **0.85** ğŸ† | **0.69** ğŸ† | **0.00** ğŸ† | 1.61          |

**Observaciones:**

- âœ… **B+ Tree** domina en casi todas las operaciones (Ã¡rbol en RAM)
- âœ… **ISAM** tiene el DELETE mÃ¡s eficiente (1.13ms vs 375ms de Sequential)
- âš ï¸ **Sequential y Ext Hash** tienen DELETE extremadamente lento (>375ms)
- âœ… Todos los Ã­ndices tienen tiempos de SELECT muy similares (~7ms)

### 5.4 Resultados: Operaciones de I/O

| Ãndice         | SELECT = (R) | RANGE (R) | INSERT (W) | DELETE (R/W)     |
| -------------- | ------------ | --------- | ---------- | ---------------- |
| **Sequential** | 1            | 1         | 1          | **449R / 0W** âš ï¸ |
| **ISAM**       | 1            | 1         | 1          | **1R / 0W** ğŸ†   |
| **Ext Hash**   | 1            | 1         | 1          | **449R / 0W** âš ï¸ |
| **B+ Tree**    | **0** ğŸ†     | **0** ğŸ†  | **0** ğŸ†   | **0R / 0W** ğŸ†   |

**Observaciones:**

- âœ… **B+ Tree** tiene 0 I/O porque el Ã¡rbol completo estÃ¡ en RAM
- âœ… **ISAM** solo necesita 1 read para DELETE (lazy deletion)
- âš ï¸ **Sequential y Ext Hash** requieren leer TODOS los bloques (449 reads) para DELETE
- âœ… Todos mantienen 1 I/O para bÃºsquedas simples (eficiente)

### 5.5 GrÃ¡ficos Comparativos

#### GrÃ¡fico 1: Tiempos de EjecuciÃ³n por OperaciÃ³n

![Benchmark Visualization](benchmark_visualization.png)

**AnÃ¡lisis del grÃ¡fico:**

- SELECT = tiene tiempos similares (~7ms) excepto B+ Tree (0.78ms)
- RANGE queries son mÃ¡s rÃ¡pidos en ISAM y B+ Tree
- INSERT es instantÃ¡neo en B+ Tree (en RAM)
- DELETE muestra la mayor diferencia: ISAM (1.13ms) vs Sequential (375ms)

#### GrÃ¡fico 2: ComparaciÃ³n General de Performance

![Benchmark Comparison](benchmark_comparison_chart.png)

**AnÃ¡lisis:**

- B+ Tree es consistentemente el mÃ¡s rÃ¡pido
- ISAM muestra buen balance entre todas las operaciones
- Sequential/Ext Hash tienen performance degradada en DELETE

#### GrÃ¡fico 3: ComparaciÃ³n de I/O

![I/O Comparison](benchmark_io_comparison.png)

**AnÃ¡lisis:**

- B+ Tree minimiza I/O al mantener todo en RAM
- ISAM usa 1 read consistente (acceso directo a buckets)
- Sequential/Ext Hash requieren muchos reads para DELETE

### 5.6 AnÃ¡lisis y DiscusiÃ³n

#### 5.6.1 BÃºsqueda por Igualdad (SELECT =)

**Resultado:** B+ Tree gana con 0.78ms (9x mÃ¡s rÃ¡pido que los demÃ¡s)

**ExplicaciÃ³n:**

- **B+ Tree** mantiene el Ã¡rbol completo en RAM, navegaciÃ³n instantÃ¡nea
- Los otros Ã­ndices requieren 1 disk read para obtener el registro
- **Ext Hash** deberÃ­a ser O(1) pero el overhead de hash penaliza
- Todos son muy eficientes (< 8ms) para 9.5K registros

**ConclusiÃ³n:** Para datasets que caben en RAM, B+ Tree es Ã³ptimo.

#### 5.6.2 BÃºsqueda por Rango (RANGE)

**Resultado:** ISAM y B+ Tree dominan (0.7-1.0ms), Sequential es competitivo

**ExplicaciÃ³n:**

- **ISAM**: Buckets ordenados permiten leer registros consecutivos eficientemente
- **B+ Tree**: Hojas enlazadas facilitan recorrido secuencial
- **Sequential**: Datos fÃ­sicamente contiguos (1 read para rango pequeÃ±o)
- **Ext Hash**: No soporta range (hash destruye orden)

**ConclusiÃ³n:** Para aplicaciones con muchos range queries, ISAM o B+ Tree.

#### 5.6.3 InserciÃ³n (INSERT)

**Resultado:** B+ Tree instantÃ¡neo (0ms), ISAM muy rÃ¡pido (0.68ms)

**ExplicaciÃ³n:**

- **B+ Tree**: InserciÃ³n en RAM sin I/O inmediato
- **ISAM**: Solo escribe en overflow (1 write), Ã­ndices en RAM
- **Sequential**: Agrega a overflow, periÃ³dicamente reconstruye (1 write)
- **Ext Hash**: Puede causar split de buckets (2 writes)

**ConclusiÃ³n:** Para aplicaciones con inserciones frecuentes, B+ Tree o ISAM.

#### 5.6.4 EliminaciÃ³n (DELETE)

**Resultado:** ISAM gana dramÃ¡ticamente (1.13ms), Sequential/Hash muy lentos (375ms)

**ExplicaciÃ³n:**

- **ISAM**: Lazy deletion - solo marca registro como eliminado (1 read, 0 writes)
- **B+ Tree**: EliminaciÃ³n en RAM, rebalanceo eficiente
- **Sequential**: Requiere rebuild completo del archivo (**449 reads!**)
- **Ext Hash**: TambiÃ©n requiere rebuild completo (**449 reads!**)

**Por quÃ© Sequential/Hash son tan lentos:**
Con 9,551 registros en bloques de ~20 registros cada uno:

- 9,551 / 20 â‰ˆ **478 bloques**
- DELETE requiere:
  1. Leer TODOS los bloques: 478 reads
  2. Filtrar el registro eliminado
  3. Reconstruir Ã­ndice completo
  4. Esta es la razÃ³n de los 449 reads observados

**ConclusiÃ³n:** Para aplicaciones con deletes frecuentes, **NUNCA usar Sequential o Ext Hash**. Usar ISAM o B+ Tree.

#### 5.6.5 ComparaciÃ³n con PredicciÃ³n TeÃ³rica

| Aspecto             | PredicciÃ³n TeÃ³rica | Resultado Experimental       | Match?     |
| ------------------- | ------------------ | ---------------------------- | ---------- |
| SELECT = mÃ¡s rÃ¡pido | Ext Hash (O(1))    | **B+ Tree** (0.78ms)         | âŒ No      |
| RANGE mÃ¡s rÃ¡pido    | Sequential         | **B+ Tree/ISAM** (0.7-1.0ms) | âš ï¸ Parcial |
| INSERT mÃ¡s rÃ¡pido   | ISAM (1 write)     | **B+ Tree** (0ms)            | âŒ No      |
| DELETE mÃ¡s rÃ¡pido   | ISAM/B+Tree        | **ISAM** (1.13ms)            | âœ… SÃ­      |

**ConclusiÃ³n:** La teorÃ­a no considerÃ³ que **B+ Tree opera completamente en RAM** para datasets pequeÃ±os-medianos, lo que le da ventaja absoluta. En datasets mÃ¡s grandes que no caben en RAM, los resultados se acercarÃ­an mÃ¡s a la predicciÃ³n teÃ³rica.

---

## 6. Interfaz GrÃ¡fica y Pruebas de Uso

### 6.1 Frontend (Streamlit)

Se desarrollÃ³ una interfaz web interactiva que permite:

**CaracterÃ­sticas:**

- âœ… Editor SQL con syntax highlighting
- âœ… Botones de ejemplo para operaciones comunes
- âœ… VisualizaciÃ³n de resultados en tabla
- âœ… MÃ©tricas de performance en tiempo real (tiempo, I/O)
- âœ… Soporte para las 4 tablas (restaurants_seq, \_isam, \_hash, \_bplustree)

**Capturas de Pantalla:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ—„ï¸ Mini Gestor de BD - Proyecto BD2                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  [ğŸ” Buscar]  [ğŸ“Š Rango]  [ğŸ“‹ Todo]  [â• Insertar]  [âŒ Eliminar]  â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ SELECT * FROM restaurants_isam WHERE "Restaurant ID" = 6300002 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                              â”‚
â”‚  [â–¶ Ejecutar Query]                                         â”‚
â”‚                                                              â”‚
â”‚  ğŸ“Š Resultados (1 registros encontrados)                    â”‚
â”‚  â±ï¸ Tiempo: 0.60 ms                                         â”‚
â”‚  ğŸ’¾ I/O: 1 reads, 0 writes                                  â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Restaurant ID â”‚ Name              â”‚ City      â”‚ Rating â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ 6300002      â”‚ Le Petit Souffle â”‚ Manila   â”‚ 4.5    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 Casos de Uso Demostrados

#### Caso 1: BÃºsqueda por ID

```sql
SELECT * FROM restaurants_isam WHERE "Restaurant ID" = 6304287
```

**Resultado:** 1 registro encontrado en 7.38ms con 1 disk read

#### Caso 2: BÃºsqueda por Rango

```sql
SELECT * FROM restaurants_isam WHERE "Restaurant ID" BETWEEN 6300000 AND 6300100
```

**Resultado:** 2 registros encontrados en 0.91ms con 1 disk read

#### Caso 3: InserciÃ³n de Restaurante

```sql
INSERT INTO restaurants_isam ("Restaurant ID", "Restaurant Name", "City")
VALUES (99999999, "Nuevo Restaurant", "Lima")
```

**Resultado:** Insertado exitosamente en 0.68ms con 1 disk write

#### Caso 4: EliminaciÃ³n

```sql
DELETE FROM restaurants_isam WHERE "Restaurant ID" = 99999999
```

**Resultado:** Eliminado en 1.13ms con 1 disk read, 0 writes

### 6.3 ComparaciÃ³n Visual de Performance

La aplicaciÃ³n permite **ejecutar la misma query en las 4 tablas** para comparar:

```
Query: SELECT * FROM [table] WHERE "Restaurant ID" = 6300002

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ãndice           â”‚ Tiempo  â”‚ I/O      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ restaurants_seq  â”‚ 7.11 ms â”‚ 1 read   â”‚
â”‚ restaurants_isam â”‚ 7.38 ms â”‚ 1 read   â”‚
â”‚ restaurants_hash â”‚ 7.41 ms â”‚ 1 read   â”‚
â”‚ restaurants_bpt  â”‚ 0.78 ms â”‚ 0 reads  â”‚ â† MÃ¡s rÃ¡pido
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 7. Conclusiones

### 7.1 Logros del Proyecto

1. âœ… **ImplementaciÃ³n exitosa de 4 tÃ©cnicas de indexaciÃ³n** con persistencia real en disco
2. âœ… **Parser SQL funcional** que soporta CREATE, SELECT, INSERT, DELETE
3. âœ… **Sistema de mÃ©tricas de I/O** que rastrea reads/writes reales
4. âœ… **Interfaz grÃ¡fica intuitiva** con Streamlit
5. âœ… **Benchmark exhaustivo** con dataset real de 9.5K registros
6. âœ… **DocumentaciÃ³n completa** con anÃ¡lisis teÃ³rico y experimental

### 7.2 Hallazgos Principales

#### Para datasets pequeÃ±os-medianos (<100K registros):

- **Ganador absoluto:** **B+ Tree** (todo en RAM, 0 I/O)
- **Mejor alternativa:** **ISAM** (balance entre todas las operaciones)

#### Para datasets grandes (>1M registros):

- **BÃºsqueda por igualdad:** Extendible Hash (O(1))
- **BÃºsqueda por rango:** B+ Tree (hojas enlazadas)
- **Inserciones frecuentes:** ISAM (1 write, sin rebuild)
- **Eliminaciones frecuentes:** **NUNCA Sequential/Hash**, usar ISAM

#### Para diferentes tipos de carga:

- **Read-heavy:** B+ Tree o Ext Hash
- **Write-heavy:** ISAM (1 write consistente)
- **Mixed workload:** B+ Tree (balance Ã³ptimo)
- **Range queries:** Sequential o B+ Tree

### 7.3 Lecciones Aprendidas

1. **La teorÃ­a no siempre coincide con la prÃ¡ctica**: B+ Tree ganÃ³ en casi todo porque el dataset cabÃ­a en RAM
2. **DELETE es crÃ­tico**: Sequential y Ext Hash son inutilizables con deletes frecuentes (375ms vs 1.13ms de ISAM)
3. **I/O es el cuello de botella**: 1 disk read = ~7ms, en RAM = 0.78ms (9x mÃ¡s rÃ¡pido)
4. **Lazy deletion es poderosa**: ISAM evita reescribir archivos completos
5. **Orden fÃ­sico importa**: Sequential es rÃ¡pido en ranges por datos contiguos

### 7.4 Trabajo Futuro

1. **Implementar RTree** para consultas espaciales (bÃºsqueda por coordenadas geogrÃ¡ficas)
2. **Agregar compactaciÃ³n en ISAM** para limpiar registros marcados como eliminados
3. **Implementar merge en B+ Tree** para manejar underfill
4. **Buffer Pool mÃ¡s sofisticado** con polÃ­ticas ARC o 2Q
5. **Soporte para transacciones** con ACID properties
6. **Query optimizer** con estadÃ­sticas y cost-based planning
7. **ParalelizaciÃ³n** de bÃºsquedas y construcciÃ³n de Ã­ndices

---

## 8. Referencias

1. Ramakrishnan, R., & Gehrke, J. (2003). _Database Management Systems_ (3rd ed.). McGraw-Hill.
2. Silberschatz, A., Korth, H. F., & Sudarshan, S. (2020). _Database System Concepts_ (7th ed.). McGraw-Hill.
3. Garcia-Molina, H., Ullman, J. D., & Widom, J. (2008). _Database Systems: The Complete Book_ (2nd ed.). Pearson.
4. Kaggle. (2024). _Restaurant Dataset_. Retrieved from https://www.kaggle.com/
5. Python Software Foundation. (2024). _Python Documentation_. https://docs.python.org/

---

## 9. Anexos

### 9.1 Repositorio del Proyecto

**GitHub:** [Link al repositorio]

**Estructura del Proyecto:**

```
Proyecto/
â”œâ”€â”€ README.md                    # DocumentaciÃ³n principal
â”œâ”€â”€ INFORME.md                   # Este informe
â”œâ”€â”€ requirements.txt             # Dependencias Python
â”œâ”€â”€ core/                        # Motor de almacenamiento
â”‚   â”œâ”€â”€ disk_manager.py
â”‚   â”œâ”€â”€ buffer_pool.py
â”‚   â”œâ”€â”€ io_metrics.py
â”‚   â”œâ”€â”€ table.py
â”‚   â””â”€â”€ schema.py
â”œâ”€â”€ indexes/                     # ImplementaciÃ³n de Ã­ndices
â”‚   â”œâ”€â”€ sequential.py
â”‚   â”œâ”€â”€ isam.py
â”‚   â”œâ”€â”€ ext_hash.py
â”‚   â””â”€â”€ bplustree.py
â”œâ”€â”€ sql/                         # Motor SQL
â”‚   â”œâ”€â”€ parser.py
â”‚   â”œâ”€â”€ executor.py
â”‚   â””â”€â”€ planner.py
â”œâ”€â”€ api/                         # Backend FastAPI
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ ui/                          # Frontend Streamlit
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ data/                        # Datasets
â”‚   â””â”€â”€ kaggle_Dataset.csv
â”œâ”€â”€ storage/                     # Archivos de datos
â”‚   â”œâ”€â”€ restaurants_seq.dat
â”‚   â”œâ”€â”€ restaurants_isam_buckets.dat
â”‚   â”œâ”€â”€ restaurants_hash.dat
â”‚   â””â”€â”€ restaurants_bplustree.dat
â”œâ”€â”€ benchmark_9k.py              # Script de benchmark
â”œâ”€â”€ visualize_benchmark.py       # GeneraciÃ³n de grÃ¡ficos
â””â”€â”€ tests/                       # Tests unitarios
    â”œâ”€â”€ test_indexes_basic.py
    â””â”€â”€ test_delete_sql.py
```

### 9.2 Instrucciones de EjecuciÃ³n

```bash
# 1. Clonar repositorio
git clone [url]
cd Proyecto

# 2. Crear entorno virtual
python -m venv .venv
.venv\Scripts\activate  # Windows

# 3. Instalar dependencias
pip install -r requirements.txt

# 4. Cargar dataset (9.5K registros)
python load_all_9k.py

# 5. Ejecutar backend API
uvicorn api.main:app --reload --port 8000

# 6. Ejecutar frontend (otra terminal)
streamlit run ui/app.py --server.port 8501

# 7. Ejecutar benchmark
python benchmark_9k.py

# 8. Generar grÃ¡ficos
python visualize_benchmark.py
```

### 9.3 Video Demostrativo

**Link al Video:** [Pendiente - 15 minutos]

**Contenido del Video:**

1. DemostraciÃ³n de la UI (SELECT, INSERT, DELETE, RANGE)
2. ComparaciÃ³n de performance entre Ã­ndices
3. ExplicaciÃ³n del cÃ³digo clave (parser, ISAM, B+ Tree)
4. AnÃ¡lisis de resultados del benchmark
5. Conclusiones y recomendaciones

---

**Fecha de Entrega:** Octubre 2025  
**Integrantes:** [Nombres de los integrantes]  
**Curso:** Bases de Datos 2 - UTEC

---

## ğŸ† Resultados Finales

âœ… **4 Ã­ndices implementados y funcionando**  
âœ… **9,551 registros procesados eficientemente**  
âœ… **B+ Tree: CampeÃ³n absoluto en performance**  
âœ… **ISAM: Mejor balance y DELETE mÃ¡s eficiente**  
âœ… **Sequential/Ext Hash: Evitar para aplicaciones con deletes**

**ConclusiÃ³n Final:** Para una aplicaciÃ³n real de restaurantes con operaciones mixtas (bÃºsquedas, inserciones, eliminaciones), **B+ Tree es la mejor opciÃ³n** si el dataset cabe en RAM. Para datasets mÃ¡s grandes, **ISAM ofrece el mejor balance** entre todas las operaciones.
