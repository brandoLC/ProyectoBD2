"""
Script para analizar archivos obsoletos en el proyecto
"""

import os
from pathlib import Path
from datetime import datetime

def get_file_info(file_path):
    """Obtener informaci√≥n de un archivo"""
    stat = file_path.stat()
    return {
        'size': stat.st_size,
        'modified': datetime.fromtimestamp(stat.st_mtime),
        'size_mb': stat.st_size / (1024 * 1024)
    }

def analyze_project():
    """Analizar proyecto y clasificar archivos"""
    
    root = Path(".")
    
    # Archivos ESENCIALES (mantener)
    essential = {
        # Core del sistema
        'core/': 'Motor de almacenamiento y gesti√≥n de I/O',
        'indexes/': 'Implementaci√≥n de los 4 √≠ndices',
        'sql/': 'Parser y executor SQL',
        'api/': 'Backend FastAPI',
        'ui/': 'Frontend Streamlit',
        
        # Configuraci√≥n
        'requirements.txt': 'Dependencias Python',
        'docker-compose.yml': 'Configuraci√≥n Docker',
        'Dockerfile.api': 'Docker para API',
        'Dockerfile.ui': 'Docker para UI',
        'Makefile': 'Comandos √∫tiles',
        
        # Documentaci√≥n principal
        'README.md': 'Documentaci√≥n principal',
        'INFORME.md': 'Informe del proyecto (CR√çTICO)',
        
        # Scripts principales
        'load_all_9k.py': 'Carga dataset de 9K registros',
        'benchmark_9k.py': 'Benchmark principal con 9K',
        'visualize_benchmark.py': 'Generaci√≥n de gr√°ficos',
        'clean_storage.py': 'Limpieza de storage',
        
        # Resultados del benchmark
        'benchmark_9k_results_1760929545.csv': 'Resultados FINALES del benchmark',
        'benchmark_visualization.png': 'Gr√°fico principal',
        'benchmark_comparison_chart.png': 'Gr√°fico comparativo',
        'benchmark_io_comparison.png': 'Gr√°fico de I/O',
        
        # Dataset principal
        'data/kaggle_Dataset .csv': 'Dataset completo (9.5K)',
        
        # Storage
        'storage/': 'Archivos de datos e √≠ndices persistentes',
    }
    
    # Archivos OBSOLETOS (pueden eliminarse)
    obsolete = {
        # Documentaci√≥n redundante
        'bd_2_proyecto_skeleton_python_fast_api_streamlit.md': 'Skeleton inicial del proyecto (ya no se usa)',
        'GUIA_USO.md': 'Gu√≠a redundante (info ya est√° en README)',
        'QUERIES_KAGGLE.md': 'Ejemplos de queries (redundante)',
        'TESTING_GUIDE.md': 'Gu√≠a de testing (redundante)',
        
        # Scripts de inicializaci√≥n obsoletos
        'init_db.py': 'Script antiguo de inicializaci√≥n (reemplazado por load_all_9k.py)',
        'init_kaggle_db.py': 'Inicializaci√≥n antigua (obsoleto)',
        'init_full_dataset.py': 'Script antiguo (reemplazado)',
        'setup_project.py': 'Setup inicial (ya no necesario)',
        
        # Benchmarks antiguos
        'benchmark_comparison.py': 'Benchmark con 100 registros (obsoleto, usar benchmark_9k.py)',
        'experiments/benchmark.py': 'Benchmark experimental (obsoleto)',
        'experiments/quick_compare.py': 'Comparaci√≥n r√°pida (obsoleto)',
        
        # Resultados antiguos de benchmarks
        'benchmark_results_1760926265.csv': 'Resultados antiguos (100 reg)',
        'benchmark_results_1760926406.csv': 'Resultados antiguos (100 reg)',
        'benchmark_results_1760928151.csv': 'Resultados antiguos (100 reg)',
        'benchmark_9k_results_1760928291.csv': 'Resultados antiguos de 9K',
        
        # Datasets redundantes
        'data/kaggle_Dataset _100.csv': 'Dataset peque√±o (redundante)',
        'data/kaggle_Dataset _1k.csv': 'Dataset mediano (redundante)',
        'data/restaurantes_100.csv': 'Dataset alternativo (no usado)',
        'data/restaurantes_1k.csv': 'Dataset alternativo (no usado)',
        'data/restaurantes_10k.csv': 'Dataset alternativo (no usado)',
        'data/sample_restaurantes.csv': 'Sample (no usado)',
        
        # Scripts de generaci√≥n de datos
        'data/download_kaggle_data.py': 'Script de descarga (ya descargado)',
        'data/generate_data.py': 'Generador de datos sint√©ticos (no usado)',
        
        # Tests de depuraci√≥n
        'test_delete_real_io.py': 'Test de debugging (ya validado)',
        'test_delete_sql.py': 'Test de debugging (ya validado)',
        'test_hash_debug.py': 'Test de debugging espec√≠fico (ya validado)',
        
        # Postman collections
        'BD2_Postman_Collection_v2.json': 'Postman v2 (redundante)',
        'BD2_Proyecto_Postman_Collection.json': 'Postman alternativo (redundante)',
        
        # Storage de pruebas
        'storage_test/': 'Storage de pruebas (no usado)',
    }
    
    print("="*80)
    print("üìä AN√ÅLISIS DE ARCHIVOS DEL PROYECTO")
    print("="*80)
    
    # Calcular tama√±os
    total_size = 0
    obsolete_size = 0
    
    for file_pattern, reason in obsolete.items():
        file_path = root / file_pattern
        if file_path.exists():
            if file_path.is_file():
                info = get_file_info(file_path)
                obsolete_size += info['size']
                total_size += info['size']
            elif file_path.is_dir():
                for f in file_path.rglob('*'):
                    if f.is_file():
                        info = get_file_info(f)
                        obsolete_size += info['size']
                        total_size += info['size']
    
    print(f"\nüì¶ Archivos ESENCIALES: {len(essential)} archivos/carpetas")
    print(f"üóëÔ∏è  Archivos OBSOLETOS: {len(obsolete)} archivos/carpetas")
    print(f"üíæ Espacio ocupado por obsoletos: {obsolete_size / (1024*1024):.2f} MB")
    
    # Listar archivos obsoletos
    print("\n" + "="*80)
    print("üóëÔ∏è  ARCHIVOS OBSOLETOS QUE PUEDEN ELIMINARSE")
    print("="*80)
    
    for file_pattern, reason in sorted(obsolete.items()):
        file_path = root / file_pattern
        if file_path.exists():
            if file_path.is_file():
                info = get_file_info(file_path)
                print(f"\nüìÑ {file_pattern}")
                print(f"   Raz√≥n: {reason}")
                print(f"   Tama√±o: {info['size_mb']:.2f} MB")
                print(f"   √öltima modificaci√≥n: {info['modified'].strftime('%Y-%m-%d %H:%M')}")
            elif file_path.is_dir():
                file_count = len(list(file_path.rglob('*')))
                print(f"\nüìÅ {file_pattern}")
                print(f"   Raz√≥n: {reason}")
                print(f"   Archivos dentro: {file_count}")
    
    # Listar archivos esenciales
    print("\n" + "="*80)
    print("‚úÖ ARCHIVOS ESENCIALES (MANTENER)")
    print("="*80)
    
    for file_pattern, description in sorted(essential.items()):
        print(f"\n‚úì {file_pattern}")
        print(f"  {description}")
    
    # Resumen
    print("\n" + "="*80)
    print("üìã RESUMEN Y RECOMENDACIONES")
    print("="*80)
    
    print(f"""
‚úÖ MANTENER ({len(essential)} items):
   - Core del sistema (core/, indexes/, sql/, api/, ui/)
   - Documentaci√≥n cr√≠tica (README.md, INFORME.md)
   - Scripts principales (load_all_9k.py, benchmark_9k.py, visualize_benchmark.py)
   - Resultados finales del benchmark (CSV + 3 PNG)
   - Dataset principal (kaggle_Dataset .csv - 9.5K registros)
   - Configuraci√≥n (requirements.txt, docker-compose.yml, Makefile)

üóëÔ∏è  ELIMINAR ({len(obsolete)} items):
   - Documentaci√≥n redundante (4 archivos .md)
   - Scripts obsoletos de inicializaci√≥n (4 archivos)
   - Benchmarks antiguos (3 scripts + 4 CSVs viejos)
   - Datasets redundantes (7 archivos CSV)
   - Tests de debugging (3 archivos)
   - Postman collections (2 archivos)
   - storage_test/ (carpeta de pruebas)

üíæ Espacio a liberar: ~{obsolete_size / (1024*1024):.2f} MB

üöÄ Beneficios de limpiar:
   1. Proyecto m√°s organizado y profesional
   2. M√°s f√°cil de navegar y entender
   3. Menos confusi√≥n sobre qu√© archivos usar
   4. Repositorio Git m√°s limpio
   5. Documentaci√≥n m√°s clara
    """)
    
    print("\n" + "="*80)
    print("üí° COMANDOS PARA ELIMINAR (REVISAR ANTES DE EJECUTAR)")
    print("="*80)
    print("""
# Documentaci√≥n redundante
Remove-Item "bd_2_proyecto_skeleton_python_fast_api_streamlit.md"
Remove-Item "GUIA_USO.md"
Remove-Item "QUERIES_KAGGLE.md"
Remove-Item "TESTING_GUIDE.md"

# Scripts obsoletos
Remove-Item "init_db.py"
Remove-Item "init_kaggle_db.py"
Remove-Item "init_full_dataset.py"
Remove-Item "setup_project.py"

# Benchmarks antiguos
Remove-Item "benchmark_comparison.py"
Remove-Item "experiments/" -Recurse
Remove-Item "benchmark_results_1760926265.csv"
Remove-Item "benchmark_results_1760926406.csv"
Remove-Item "benchmark_results_1760928151.csv"
Remove-Item "benchmark_9k_results_1760928291.csv"

# Datasets redundantes
Remove-Item "data/kaggle_Dataset _100.csv"
Remove-Item "data/kaggle_Dataset _1k.csv"
Remove-Item "data/restaurantes_*.csv"
Remove-Item "data/sample_restaurantes.csv"
Remove-Item "data/download_kaggle_data.py"
Remove-Item "data/generate_data.py"

# Tests de debugging
Remove-Item "test_delete_real_io.py"
Remove-Item "test_delete_sql.py"
Remove-Item "test_hash_debug.py"

# Postman
Remove-Item "BD2_Postman_Collection_v2.json"
Remove-Item "BD2_Proyecto_Postman_Collection.json"

# Storage de pruebas
Remove-Item "storage_test/" -Recurse
    """)

if __name__ == "__main__":
    analyze_project()
